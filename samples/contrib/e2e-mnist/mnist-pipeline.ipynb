{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHXbaaI0ILgM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install https://storage.googleapis.com/ml-pipeline/release/latest/kfp.tar.gz --upgrade --user\n",
        "!pip3 install Pillow --upgrade --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG0amTibILgO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from string import Template\n",
        "\n",
        "import kfp\n",
        "from kfp import components\n",
        "from kfp.components import func_to_container_op\n",
        "import kfp.dsl as dsl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0ssbEM5ILgP"
      },
      "outputs": [],
      "source": [
        "def convert_mnist_experiment_result(experiment_result) -> str:\n",
        "    import json\n",
        "    r = json.loads(experiment_result)\n",
        "    args = []\n",
        "    for hp in r:\n",
        "        print(hp)\n",
        "        args.append(\"%s=%s\" % (hp[\"name\"], hp[\"value\"]))\n",
        "\n",
        "    return \" \".join(args)\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name=\"End to end pipeline\",\n",
        "    description=\"An end to end example including hyperparameter tuning, train and inference.\"\n",
        ")\n",
        "def mnist_pipeline(\n",
        "        name=\"mnist-{{workflow.uid}}\",\n",
        "        namespace=\"kubeflow\",\n",
        "        step=2000):\n",
        "    # step 1: create a Katib experiment to tune hyperparameters\n",
        "    objectiveConfig = {\n",
        "      \"type\": \"minimize\",\n",
        "      \"goal\": 0.001,\n",
        "      \"objectiveMetricName\": \"loss\",\n",
        "    }\n",
        "    algorithmConfig = {\"algorithmName\" : \"random\"}\n",
        "    parameters = [\n",
        "      {\"name\": \"--tf-learning-rate\", \"parameterType\": \"double\", \"feasibleSpace\": {\"min\": \"0.01\",\"max\": \"0.03\"}},\n",
        "      {\"name\": \"--tf-batch-size\", \"parameterType\": \"discrete\", \"feasibleSpace\": {\"list\": [\"16\", \"32\", \"64\"]}},\n",
        "    ]\n",
        "    rawTemplate = {\n",
        "      \"apiVersion\": \"kubeflow.org/v1\",\n",
        "      \"kind\": \"TFJob\",\n",
        "      \"metadata\": {\n",
        "         \"name\": \"{{.Trial}}\",\n",
        "         \"namespace\": \"{{.NameSpace}}\"\n",
        "      },\n",
        "      \"spec\": {\n",
        "        \"tfReplicaSpecs\": {\n",
        "          \"Chief\": {\n",
        "            \"replicas\": 1,\n",
        "            \"restartPolicy\": \"OnFailure\",\n",
        "            \"template\": {\n",
        "              \"spec\": {\n",
        "                \"containers\": [\n",
        "                {\n",
        "                  \"command\": [\n",
        "                    \"sh\",\n",
        "                    \"-c\"\n",
        "                  ],\n",
        "                  \"args\": [\n",
        "                    \"python ./model.py --tf-train-steps=2000 {{- with .HyperParameters}} {{- range .}} {{.Name}}={{.Value}} {{- end}} {{- end}}\"\n",
        "                  ],\n",
        "                  \"image\": \"liuhougangxa/tf-estimator-mnist\",\n",
        "                  \"name\": \"tensorflow\"\n",
        "                }\n",
        "                ]\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"Worker\": {\n",
        "            \"replicas\": 3,\n",
        "            \"restartPolicy\": \"OnFailure\",\n",
        "            \"template\": {\n",
        "              \"spec\": {\n",
        "                \"containers\": [\n",
        "                {\n",
        "                  \"command\": [\n",
        "                    \"sh\",\n",
        "                    \"-c\"\n",
        "                  ],\n",
        "                  \"args\": [\n",
        "                    \"python ./model.py --tf-train-steps=2000 {{- with .HyperParameters}} {{- range .}} {{.Name}}={{.Value}} {{- end}} {{- end}}\"\n",
        "                  ],\n",
        "                  \"image\": \"liuhougangxa/tf-estimator-mnist\",\n",
        "                  \"name\": \"tensorflow\"\n",
        "                }\n",
        "                ]\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    trialTemplate = {\n",
        "      \"goTemplate\": {\n",
        "        \"rawTemplate\": json.dumps(rawTemplate)\n",
        "      }\n",
        "    }\n",
        "\n",
        "    metricsCollectorSpec = {\n",
        "      \"source\": {\n",
        "        \"fileSystemPath\": {\n",
        "          \"path\": \"/tmp/tf\",\n",
        "          \"kind\": \"Directory\"\n",
        "        }\n",
        "      },\n",
        "      \"collector\": {\n",
        "        \"kind\": \"TensorFlowEvent\"\n",
        "      }\n",
        "    }\n",
        "\n",
        "    katib_experiment_launcher_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/katib-launcher/component.yaml')\n",
        "    op1 = katib_experiment_launcher_op(\n",
        "            experiment_name=name,\n",
        "            experiment_namespace=namespace,\n",
        "            parallel_trial_count=3,\n",
        "            max_trial_count=12,\n",
        "            objective=str(objectiveConfig),\n",
        "            algorithm=str(algorithmConfig),\n",
        "            trial_template=str(trialTemplate),\n",
        "            parameters=str(parameters),\n",
        "            metrics_collector=str(metricsCollectorSpec),\n",
        "            # experiment_timeout_minutes=experimentTimeoutMinutes,\n",
        "            delete_finished_experiment=False)\n",
        "\n",
        "    # step2: create a TFJob to train your model with best hyperparameter tuned by Katib\n",
        "    tfjobjson_template = Template(\"\"\"\n",
        "{\n",
        "  \"apiVersion\": \"kubeflow.org/v1\",\n",
        "  \"kind\": \"TFJob\",\n",
        "  \"metadata\": {\n",
        "    \"name\": \"$name\",\n",
        "    \"namespace\": \"$namespace\"\n",
        "  },\n",
        "  \"spec\": {\n",
        "    \"tfReplicaSpecs\": {\n",
        "      \"Chief\": {\n",
        "        \"replicas\": 1,\n",
        "        \"restartPolicy\": \"OnFailure\",\n",
        "        \"template\": {\n",
        "          \"spec\": {\n",
        "            \"volumes\": [\n",
        "              {\n",
        "                \"name\": \"export-model\",\n",
        "                \"persistentVolumeClaim\": {\n",
        "                  \"claimName\": \"$modelpvc\"\n",
        "                }\n",
        "              }\n",
        "            ],\n",
        "            \"containers\": [\n",
        "              {\n",
        "                \"command\": [\n",
        "                  \"sh\",\n",
        "                  \"-c\"\n",
        "                ],\n",
        "                \"args\": [\n",
        "                  \"python ./model.py --tf-train-steps=$step --tf-export-dir=/mnt/export $args\"\n",
        "                ],\n",
        "                \"image\": \"liuhougangxa/tf-estimator-mnist\",\n",
        "                \"name\": \"tensorflow\",\n",
        "                \"volumeMounts\": [\n",
        "                  {\n",
        "                    \"mountPath\": \"/mnt/export\",\n",
        "                    \"name\": \"export-model\"\n",
        "                  }\n",
        "                ]\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"Worker\": {\n",
        "        \"replicas\": 3,\n",
        "        \"restartPolicy\": \"OnFailure\",\n",
        "        \"template\": {\n",
        "          \"spec\": {\n",
        "            \"volumes\": [\n",
        "              {\n",
        "                \"name\": \"export-model\",\n",
        "                \"persistentVolumeClaim\": {\n",
        "                  \"claimName\": \"$modelpvc\"\n",
        "                }\n",
        "              }\n",
        "            ],\n",
        "            \"containers\": [\n",
        "              {\n",
        "                \"command\": [\n",
        "                  \"sh\",\n",
        "                  \"-c\"\n",
        "                ],\n",
        "                \"args\": [\n",
        "                  \"python ./model.py --tf-train-steps=$step --tf-export-dir=/mnt/export $args\"\n",
        "                ],\n",
        "                \"image\": \"liuhougangxa/tf-estimator-mnist\",\n",
        "                \"name\": \"tensorflow\",\n",
        "                \"volumeMounts\": [\n",
        "                  {\n",
        "                    \"mountPath\": \"/mnt/export\",\n",
        "                    \"name\": \"export-model\"\n",
        "                  }\n",
        "                ]\n",
        "              }\n",
        "            ]\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "    convert_op = func_to_container_op(convert_mnist_experiment_result)\n",
        "    op2 = convert_op(op1.output)\n",
        "\n",
        "    modelvolop = dsl.VolumeOp(\n",
        "        name=\"modelpvc\",\n",
        "        resource_name=\"modelpvc\",\n",
        "        size=\"1Gi\",\n",
        "        modes=dsl.VOLUME_MODE_RWM\n",
        "    )\n",
        "\n",
        "    tfjobjson = tfjobjson_template.substitute(\n",
        "            {'args': op2.output,\n",
        "             'name': name,\n",
        "             'namespace': namespace,\n",
        "             'step': step,\n",
        "             'modelpvc': modelvolop.outputs[\"name\"]\n",
        "            })\n",
        "\n",
        "    tfjob = json.loads(tfjobjson)\n",
        "\n",
        "    train = dsl.ResourceOp(\n",
        "        name=\"train\",\n",
        "        k8s_resource=tfjob,\n",
        "        success_condition='status.replicaStatuses.Worker.succeeded==3,status.replicaStatuses.Chief.succeeded==1'\n",
        "    )\n",
        "\n",
        "    # step 3: model inferencese by KFServing Inferenceservice\n",
        "    inferenceservice_template = Template(\"\"\"\n",
        "{\n",
        "  \"apiVersion\": \"serving.kubeflow.org/v1alpha2\",\n",
        "  \"kind\": \"InferenceService\",\n",
        "  \"metadata\": {\n",
        "    \"name\": \"mnist-{{workflow.uid}}\"\n",
        "  },\n",
        "  \"spec\": {\n",
        "    \"default\": {\n",
        "      \"predictor\": {\n",
        "        \"tensorflow\": {\n",
        "          \"storageUri\": \"pvc://$modelpvc/\"\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "    inferenceservicejson = inferenceservice_template.substitute({'modelpvc': modelvolop.outputs[\"name\"]})\n",
        "    inferenceservice =  json.loads(inferenceservicejson)\n",
        "    inference = dsl.ResourceOp(\n",
        "      name=\"inference\",\n",
        "      k8s_resource=inferenceservice,\n",
        "      success_condition='status.url').after(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TEJGKEqILgQ"
      },
      "outputs": [],
      "source": [
        "pipeline = kfp.Client().create_run_from_pipeline_func(mnist_pipeline, arguments={})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YSHTdp9ILgQ"
      },
      "source": [
        "1. When the pipeline done, you can get `inferenceservice` name in the pipeline output section as below, for example in this case as the picture shows in my cluster, the `inference-name` is `mnist-49570eac-1a81-484c-8eec-081c77082696`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_xWn_LWILgR"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuwKM1nvILgS"
      },
      "source": [
        "2. Download a mnist picture for inference test, such as 9.bmp from [here](https://raw.githubusercontent.com/hougangliu/pipelines/e2e-pipeline-sample/samples/contrib/e2e-mnist/9.bmp). Then upload it to the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ8Zq5RHILgS",
        "outputId": "2c60ee36-fa85-41c0-eb1c-53209859cea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'predictions': [{'predictions': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], 'classes': 9}]}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Get inference_name as above step 1\n",
        "inference_name = \"mnist-49570eac-1a81-484c-8eec-081c77082696\"\n",
        "# Get cluster_ip by \"kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.clusterIP}'\"\n",
        "cluster_ip = \"10.0.244.12\"\n",
        "# image_file is the mnist picture uploaded as above step 2\n",
        "image_file = '9.bmp'\n",
        "data = np.array(Image.open(image_file).convert('L').resize((28, 28))).astype(np.float).reshape(-1, 28, 28, 1)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "json_request = '{{ \"instances\" : {} }}'.format(np.array2string(data, separator=',', formatter={'float':lambda x: \"%.1f\" % x}))\n",
        "headers={\"Host\": \"%s.kubeflow.example.com\" % inference_name}\n",
        "\n",
        "response = requests.post(\"http://%s/v1/models/%s:predict\" % (cluster_ip, inference_name), data = json_request, headers = headers)\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM_mBNbRILgS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}